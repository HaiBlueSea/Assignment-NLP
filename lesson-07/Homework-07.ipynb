{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新华社新闻抄袭自动判别\n",
    "任务要求：\n",
    "1. 构建一个机器学习模型，判断这个文章是不是新华社的\n",
    "2. 当这个模型的acc 大于 0.8778， recall， precision，f1等值都较高的时候\n",
    "3. 用该模型 判断一篇文章是否是新华社的文章，如果判断出来是新华社的，但是，它的source并不是新华社的，那么，我们就说，这个文章是抄袭的新华社的文章\n",
    "4. Text Representation uses \"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'E:\\\\MYGIT\\\\DataSources\\\\sqlResult_1558435.csv'\n",
    "pandas_data = pd.read_csv(filename, encoding='gb18030')\n",
    "pandas_data = pandas_data.dropna(subset = ['content']) #剔除内容为空的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pandas_data['content'].tolist()\n",
    "source = pandas_data['source'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = [name if isinstance(name, str) else 'unknow' for name in source] #把没有来源的信息标记为unknow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### content清洗切词，source分好标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_labels = [1 if name.strip() == '新华社' else 0 for name in source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78661 87054 87054\n"
     ]
    }
   ],
   "source": [
    "print(sum(article_labels), len(article_labels),len(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上可见正负样本非常不均衡，如何解决？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyltp import Segmentor\n",
    "#获取停用词集\n",
    "def get_stopwords():\n",
    "    stopwords = []\n",
    "    with open('stopwords.txt') as f:\n",
    "        line_str = f.readline()\n",
    "        while line_str!= '':\n",
    "            line_str = line_str.strip()\n",
    "            stopwords.append(line_str)\n",
    "            line_str = f.readline()\n",
    "    return set(stopwords)\n",
    "\n",
    "def text_deal_cut(text_list):\n",
    "    stopwords = get_stopwords()\n",
    "    cws_model_path = 'E:/MYGIT/Project/ltp_data/cws.model'\n",
    "    \n",
    "    segmentor = Segmentor()  # 初始化实例\n",
    "    segmentor.load(cws_model_path)  # 加载模型 \n",
    "    corpus = []\n",
    "    i = 0\n",
    "    for string in text_list:\n",
    "        i += 1\n",
    "        if(i%3000 == 0):print(i)\n",
    "        string = string.strip()\n",
    "        string_temp = ''\n",
    "        words = list(segmentor.segment(string))\n",
    "        for word in words:\n",
    "            if word not in stopwords:\n",
    "                string_temp += word + ' '    \n",
    "        corpus.append(string_temp)\n",
    "    segmentor.release()  # 释放模型\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87054"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n"
     ]
    }
   ],
   "source": [
    "corpus = text_deal_cut(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到目前为止，已经获得了处理好的标签，和分词好的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./temp_file/corpus_list','wb') as f:\n",
    "    pickle.dump(corpus,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取\n",
    "import pickle\n",
    "try:\n",
    "    print(corpus[0])\n",
    "except NameError:\n",
    "    with open('./temp_file/corpus_list','rb') as f:\n",
    "        corpus = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'本周 6月 12日 小米 手机 15 款 机型 外 机型 暂停 更新 发布 含 开发版 体验版 内测 稳定 版 暂 受 影响 确保 工程师 精力 系统 优化 工作 有人 猜测 精力 主要 MIUI 研发 之中 \\r\\n MIUI 去年 5月 发布 年 有余 更新换代 。\\r\\n MIUI 确切 信息 等待 官方 消息 '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'本周 6月 12日 小米 手机 15 款 机型 外 机型 暂停 更新 发布 含 开发版 体验版 内测 稳定 版 暂 受 影响 确保 工程师 精力 系统 优化 工作 有人 猜测 精力 主要 MIUI 研发 之中  MIUI 去年 5月 发布 年 有余 更新换代  MIUI 确切 信息 等待 官方 消息 '"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.replace('\\r\\n','').replace('。','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'本周 6月 12日 小米 手机 15 款 机型 外 机型 暂停 更新 发布 含 开发版 体验版 内测 稳定 版 暂 受 影响 确保 工程师 精力 系统 优化 工作 有人 猜测 精力 主要 MIUI 研发 之中  MIUI 去年 5月 发布 年 有余 更新换代  MIUI 确切 信息 等待 官方 消息 '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [line.replace('\\r\\n','').replace('。','') for line in corpus]\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = TfidfVectorizer(max_features= 10000) #设置文本单词个数最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples = corpus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorized.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87054, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(article_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def logical_model(X,y,test_rate=0.4):\n",
    "    X_train, X_test, y_train, y_test = train_test_split\\\n",
    "    (X, y, test_size=test_rate, random_state=0)\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_prob_y = clf.predict(X_test)\n",
    "    acc = metrics.precision_score(y_test, predict_prob_y)\n",
    "    recall = metrics.recall_score(y_test, predict_prob_y)\n",
    "    f1 = metrics.f1_score(y_test, predict_prob_y)\n",
    "    auc = metrics.roc_auc_score(y_test, predict_prob_y)\n",
    "    return [acc,recall,f1,auc]\n",
    "    #print(classification_report(y_test, predict_prob_y))\n",
    "\n",
    "class Logical_model:\n",
    "    def __init__(self,corpus,y):\n",
    "        self.vectorized, self.model = self.__build_model(corpus, y)\n",
    "        \n",
    "    def __build_model(self,corpus,y):\n",
    "        vectorized = TfidfVectorizer(max_features= 10000)\n",
    "        X = vectorized.fit_transform(corpus)\n",
    "        clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "        clf.fit(X,y)\n",
    "        return vectorized, clf\n",
    "    \n",
    "    def predict(self, input_corpus):\n",
    "        #input_corpus should be a list or array\n",
    "        X = self.vectorized.transform(input_corpus)\n",
    "        predict_prob_y = self.model.predict(X)\n",
    "        return predict_prob_y\n",
    "    def is_copy(self, input_corpus, true_label):\n",
    "        input_corpus = [input_corpus]\n",
    "        X = self.vectorized.transform(input_corpus)\n",
    "        predict_prob_y = self.model.predict(X)\n",
    "        \n",
    "        if predict_prob_y[0]==1 and true_label==0:\n",
    "            print('This article is cpoyed')\n",
    "        else:\n",
    "            print('This article is ture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Regression = logical_model(X,y,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = Logical_model(corpus, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:[0 0 0 0 0 0 0 0] \n",
      "   True:[0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('predict:{} \\n   True:{}'.format(logistic_model.predict(corpus[12:20]), y[12:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = logistic_model.predict(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "test_index = []\n",
    "for i in range(len(y)):\n",
    "    if predict_label[i] != y[i] and y[i]==0:\n",
    "        error += 1\n",
    "        test_index.append(i)\n",
    "        #print(i)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6050\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_index = random.choice(test_index)\n",
    "print(random_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article is cpoyed\n"
     ]
    }
   ],
   "source": [
    "logistic_model.is_copy(corpus[random_index], y[random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article is ture\n"
     ]
    }
   ],
   "source": [
    "logistic_model.is_copy(corpus[500], y[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": [
     1,
     15
    ]
   },
   "outputs": [],
   "source": [
    "#模型参数获取\n",
    "def Knn_model(X, y,test_rate=0.4):    \n",
    "    X_train, X_test, y_train, y_test = train_test_split\\\n",
    "    (X, y, test_size=test_rate, random_state=0) \n",
    "    neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    predict_prob_y = neigh.predict(X_test)\n",
    "    acc = metrics.precision_score(y_test, predict_prob_y)\n",
    "    recall = metrics.recall_score(y_test, predict_prob_y)\n",
    "    f1 = metrics.f1_score(y_test, predict_prob_y)\n",
    "    auc = metrics.roc_auc_score(y_test, predict_prob_y)\n",
    "    return [acc,recall,f1,auc]\n",
    "    #print(classification_report(y_test, predict_prob_y))\n",
    "\n",
    "#模型\n",
    "class Knn_Model:\n",
    "    def __init__(self,corpus,y):\n",
    "        self.vectorized, self.model = self.__build_model(corpus, y)\n",
    "        \n",
    "    def __build_model(self,corpus,y):\n",
    "        vectorized = TfidfVectorizer(max_features= 10000)\n",
    "        X = vectorized.fit_transform(corpus)\n",
    "        neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "        neigh.fit(X,y)\n",
    "        return vectorized, neigh\n",
    "    \n",
    "    def predict(self, input_corpus):\n",
    "        #input_corpus should be a list or array\n",
    "        X = self.vectorized.transform(input_corpus)\n",
    "        predict_prob_y = self.model.predict(X)\n",
    "        return predict_prob_y\n",
    "    def is_copy(self, input_corpus, true_label):\n",
    "        input_corpus = [input_corpus]\n",
    "        X = self.vectorized.transform(input_corpus)\n",
    "        predict_prob_y = self.model.predict(X)\n",
    "        \n",
    "        if predict_prob_y[0]==1 and true_label==0:\n",
    "            print('This article is cpoyed')\n",
    "        else:\n",
    "            print('This article is ture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = Knn_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = Knn_Model(corpus, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predict:{} \\n   True:{}'.format(logistic_model.predict(corpus[12:20]), y[12:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = knn_model.predict(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87054 87054\n"
     ]
    }
   ],
   "source": [
    "print(len(predict_label), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4499\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "test_index = []\n",
    "for i in range(len(y)):\n",
    "    if predict_label[i] != y[i] and y[i]==0:\n",
    "        error += 1\n",
    "        test_index.append(i)\n",
    "        #print(i)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6274\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_index = random.choice(test_index)\n",
    "print(random_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article is cpoyed\n"
     ]
    }
   ],
   "source": [
    "knn_model.is_copy(corpus[random_index], y[random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "515 in test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article is ture\n"
     ]
    }
   ],
   "source": [
    "knn_model.is_copy(corpus[515], y[515])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较结果：\n",
    "1. 限制Tfidf向量大小,而不是按输入数据最大值，一定程度上不影响结果\n",
    "2. 这是因为sklearn模块先对词排序，选取词频前n个词作为 Tfidf的向量元素\n",
    "3. 对于在整个corpus中出现次数极少的词对文章影响比较小\n",
    "\n",
    "max_features : int or None (default=None)\n",
    "\n",
    "    If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = np.array([Logistic_Regression, KNN])\n",
    "colums = ['ACC', 'RECALL','F1','AUC']\n",
    "index = ['Logistic_Regression', 'KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(array_2d, index=index, columns=colums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic_Regression</th>\n",
       "      <td>0.973997</td>\n",
       "      <td>0.996983</td>\n",
       "      <td>0.985356</td>\n",
       "      <td>0.872967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.925957</td>\n",
       "      <td>0.995394</td>\n",
       "      <td>0.959421</td>\n",
       "      <td>0.622323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ACC    RECALL        F1       AUC\n",
       "Logistic_Regression  0.973997  0.996983  0.985356  0.872967\n",
       "KNN                  0.925957  0.995394  0.959421  0.622323"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据以上结果，选择逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
